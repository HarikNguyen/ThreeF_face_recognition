{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8_nnZihFPZ0",
        "outputId": "d89d030e-6b43-42e0-fd3e-06b85dd8a169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4cvsaqQFSsr"
      },
      "outputs": [],
      "source": [
        "!cp /content/gdrive/MyDrive/kaggle.json /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7spZEaGD8qgY"
      },
      "source": [
        "# Preparations\n",
        "- Download dataset for training, validating. We train with CASIA-webface from kaggle and test with self-collect our friend and friends of our friend faces (called by ThreeF dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ollPRTEv-qW",
        "outputId": "8d0bc970-46c4-4b0b-e367-5bf58d1e311e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ThreeF'...\n",
            "remote: Enumerating objects: 1398, done.\u001b[K\n",
            "remote: Total 1398 (delta 0), reused 0 (delta 0), pack-reused 1398\u001b[K\n",
            "Receiving objects: 100% (1398/1398), 42.99 MiB | 15.31 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "!git clone https://github.com/HarikNguyen/ThreeF.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUN21GFkFx2w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B45IG5XTGUX1",
        "outputId": "22425971-c74c-4ab5-8cbc-7a6dafeea4e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF4MWK1wFgfQ",
        "outputId": "3acafca2-5f19-4c6a-d21d-e35b6b1a971c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading casia-webface.zip to /content\n",
            "100% 2.53G/2.53G [02:00<00:00, 24.2MB/s]\n",
            "100% 2.53G/2.53G [02:00<00:00, 22.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d ntl0601/casia-webface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7j4WMf0kFoGO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip \\*.zip  && rm *.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGy5j2xk-Ye2"
      },
      "source": [
        "# Create dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwUrUGvRoBzF"
      },
      "source": [
        "## Get imgage list in casia_webface dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8B7JXSvFtM4"
      },
      "outputs": [],
      "source": [
        "# define get leaf path\n",
        "def get_leaf_paths(root_dir):\n",
        "  leaf_paths = []\n",
        "\n",
        "  for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    if not dirnames and filenames:\n",
        "      for filename in filenames:\n",
        "        leaf_path = os.path.join(dirpath, filename)\n",
        "        leaf_paths.append(leaf_path)\n",
        "\n",
        "  return leaf_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX2L1KEVCCBu"
      },
      "outputs": [],
      "source": [
        "# get img_list in casia_webface dataset\n",
        "casia_webface_df = pd.read_csv(\"/content/casia-webface.txt\",\n",
        "                 sep=\"\\s+\",\n",
        "                 header=None)\n",
        "casia_webface_paths = \"/content/\" + casia_webface_df[1]\n",
        "\n",
        "# get img_list in ThreeF dataset\n",
        "\n",
        "threeF_paths = get_leaf_paths(\"/content/ThreeF\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjB-YYew-oL1",
        "outputId": "c639d701-d78d-4e72-a3f6-4fd0cdd480d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1336"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "casia_webface_df.iloc[100000][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cfnnkzmHx_3",
        "outputId": "00550865-7817-45fd-fb73-7932f84a9517"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10537"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print the number of person\n",
        "num_o_pers = casia_webface_df[0].unique().shape[0]\n",
        "num_o_pers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3tb9G_FHEUu",
        "outputId": "c1ed1213-516a-48d9-bb2b-494672c8cd28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max: 786 min: 2 average: 43.69478978836481\n"
          ]
        }
      ],
      "source": [
        "M = np.max(casia_webface_df[0].value_counts())\n",
        "m = np.min(casia_webface_df[0].value_counts())\n",
        "avg = np.average(casia_webface_df[0].value_counts())\n",
        "print(f\"max: {M}\", f\"min: {m}\", f\"average: {avg}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sctUpjcr9PIa",
        "outputId": "060cb260-3acd-449d-c9a6-3932b206c282"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(661,)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "threeF_paths = np.array(threeF_paths)\n",
        "threeF_paths.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_48k87y49beo",
        "outputId": "f32bc0eb-7e8a-4e14-e51d-e89701ff1982"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(460412,)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "casia_webface_paths.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cQKJMHmVAx6"
      },
      "source": [
        "# Define MobileNet model and Arcface loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnpopX-BwgIF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iC-LrrSVNFE"
      },
      "source": [
        "## MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEfjxasMCoZb"
      },
      "outputs": [],
      "source": [
        "class Hswish(nn.Module):\n",
        "  def forward(self, x):\n",
        "    out = x * F.relu6(x + 3, inplace=True) / 6\n",
        "    return out\n",
        "\n",
        "class Hsigmoid(nn.Module):\n",
        "  def forward(self, x):\n",
        "    out = F.relu6(x + 3, inplace=True) / 6\n",
        "    return out\n",
        "\n",
        "class SeModule(nn.Module):\n",
        "  def __init__(self, in_size, reduction=4):\n",
        "    super(SeModule, self).__init__()\n",
        "    expand_size =  max(in_size // reduction, 8)\n",
        "    self.se = nn.Sequential(\n",
        "      nn.AdaptiveAvgPool2d(1),\n",
        "      nn.Conv2d(in_size,\n",
        "                expand_size,\n",
        "                kernel_size=1,\n",
        "                bias=False),\n",
        "      nn.BatchNorm2d(expand_size),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(expand_size,\n",
        "                in_size,\n",
        "                kernel_size=1,\n",
        "                bias=False),\n",
        "      nn.Hardsigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x * self.se(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "  '''expand + depthwise + pointwise'''\n",
        "  def __init__(self,\n",
        "               kernel_size,\n",
        "               in_size,\n",
        "               expand_size,\n",
        "               out_size,\n",
        "               act,\n",
        "               se,\n",
        "               stride):\n",
        "    super(Block, self).__init__()\n",
        "    self.stride = stride\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_size,\n",
        "                           expand_size,\n",
        "                           kernel_size=1,\n",
        "                           bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(expand_size)\n",
        "    self.act1 = act(inplace=True)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(expand_size,\n",
        "                           expand_size,\n",
        "                           kernel_size=kernel_size,\n",
        "                           stride=stride,\n",
        "                           padding=kernel_size//2,\n",
        "                           groups=expand_size,\n",
        "                           bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(expand_size)\n",
        "    self.act2 = act(inplace=True)\n",
        "    self.se = SeModule(expand_size) if se else nn.Identity()\n",
        "\n",
        "    self.conv3 = nn.Conv2d(expand_size,\n",
        "                           out_size,\n",
        "                           kernel_size=1,\n",
        "                           bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(out_size)\n",
        "    self.act3 = act(inplace=True)\n",
        "\n",
        "    self.skip = None\n",
        "    if stride == 1 and in_size != out_size:\n",
        "      self.skip = nn.Sequential(\n",
        "        nn.Conv2d(in_size,\n",
        "                  out_size,\n",
        "                  kernel_size=1,\n",
        "                  bias=False),\n",
        "        nn.BatchNorm2d(out_size)\n",
        "      )\n",
        "\n",
        "    if stride == 2 and in_size != out_size:\n",
        "      self.skip = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_size,\n",
        "                  out_channels=in_size,\n",
        "                  kernel_size=3,\n",
        "                  groups=in_size,\n",
        "                  stride=2,\n",
        "                  padding=1,\n",
        "                  bias=False),\n",
        "        nn.BatchNorm2d(in_size),\n",
        "        nn.Conv2d(in_size,\n",
        "                  out_size,\n",
        "                  kernel_size=1,\n",
        "                  bias=True),\n",
        "        nn.BatchNorm2d(out_size)\n",
        "      )\n",
        "\n",
        "    if stride == 2 and in_size == out_size:\n",
        "        self.skip = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_size,\n",
        "                  out_channels=out_size,\n",
        "                  kernel_size=3,\n",
        "                  groups=in_size,\n",
        "                  stride=2,\n",
        "                  padding=1,\n",
        "                  bias=False),\n",
        "        nn.BatchNorm2d(out_size)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    skip = x\n",
        "\n",
        "    out = self.act1(self.bn1(self.conv1(x)))\n",
        "    out = self.act2(self.bn2(self.conv2(out)))\n",
        "    out = self.se(out)\n",
        "    out = self.bn3(self.conv3(out))\n",
        "\n",
        "    if self.skip is not None:\n",
        "      skip = self.skip(skip)\n",
        "    return self.act3(out + skip)\n",
        "\n",
        "class MobileNetV3_Small(nn.Module):\n",
        "  def __init__(self,\n",
        "               num_classes=1000,\n",
        "               act=nn.Hardswish):\n",
        "    super(MobileNetV3_Small, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,\n",
        "                           16,\n",
        "                           kernel_size=3,\n",
        "                           stride=2,\n",
        "                           padding=1,\n",
        "                           bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(16)\n",
        "    self.hs1 = act(inplace=True)\n",
        "\n",
        "    self.bneck = nn.Sequential(\n",
        "      Block(3, 16, 16, 16, nn.ReLU, True, 2),\n",
        "      Block(3, 16, 72, 24, nn.ReLU, False, 2),\n",
        "      Block(3, 24, 88, 24, nn.ReLU, False, 1),\n",
        "      Block(5, 24, 96, 40, act, True, 2),\n",
        "      Block(5, 40, 240, 40, act, True, 1),\n",
        "      Block(5, 40, 240, 40, act, True, 1),\n",
        "      Block(5, 40, 120, 48, act, True, 1),\n",
        "      Block(5, 48, 144, 48, act, True, 1),\n",
        "      Block(5, 48, 288, 96, act, True, 2),\n",
        "      Block(5, 96, 576, 96, act, True, 1),\n",
        "      Block(5, 96, 576, 96, act, True, 1),\n",
        "    )\n",
        "\n",
        "    self.conv2 = nn.Conv2d(96,\n",
        "                           576,\n",
        "                           kernel_size=1,\n",
        "                           stride=1,\n",
        "                           padding=0,\n",
        "                           bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(576)\n",
        "    self.hs2 = act(inplace=True)\n",
        "    self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    self.linear3 = nn.Linear(576, 1280, bias=False)\n",
        "    self.bn3 = nn.BatchNorm1d(1280)\n",
        "    self.hs3 = act(inplace=True)\n",
        "    self.drop = nn.Dropout(0.2)\n",
        "    self.linear4 = nn.Linear(1280, num_classes)\n",
        "    self.init_params()\n",
        "\n",
        "  def init_params(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "        if m.bias is not None:\n",
        "          init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        init.normal_(m.weight, std=0.001)\n",
        "        if m.bias is not None:\n",
        "          init.constant_(m.bias, 0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.hs1(self.bn1(self.conv1(x)))\n",
        "    out = self.bneck(out)\n",
        "\n",
        "    out = self.hs2(self.bn2(self.conv2(out)))\n",
        "    out = self.gap(out).flatten(1)\n",
        "    out = self.drop(self.hs3(self.bn3(self.linear3(out))))\n",
        "\n",
        "    return self.linear4(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haqG3NRRbCPf"
      },
      "outputs": [],
      "source": [
        "class ArcFaceLoss(nn.Module):\n",
        "  def __init__(self,\n",
        "               embedding_size,\n",
        "               num_classes,\n",
        "               margin=0.5,\n",
        "               scale=64):\n",
        "    super(ArcFaceLoss, self).__init__()\n",
        "    self.embedding_size = embedding_size\n",
        "    self.num_classes = num_classes\n",
        "    self.margin = margin\n",
        "    self.scale = scale\n",
        "\n",
        "    self.weights = nn.Parameter(torch.FloatTensor(num_classes, embedding_size))\n",
        "    nn.init.xavier_uniform_(self.weights)\n",
        "\n",
        "  def forward(self, embeddings, targets):\n",
        "    # Normalize the input embeddings and weights\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "    weights = F.normalize(self.weights, p=2, dim=1)\n",
        "\n",
        "    # Compute the cosine similarity between embeddings and weights\n",
        "    cos_theta = torch.matmul(embeddings, weights.t())\n",
        "    cos_theta = torch.clamp(cos_theta, -1.0, 1.0)\n",
        "\n",
        "    # Get the target class weights\n",
        "    target_weights = weights[targets]\n",
        "\n",
        "    # Compute the margin term\n",
        "    theta = torch.acos(cos_theta)\n",
        "    margin_theta = theta + self.margin\n",
        "\n",
        "    # Compute the final logits with the margin term\n",
        "    logits = torch.cos(margin_theta)\n",
        "    logits *= self.scale\n",
        "\n",
        "    # Compute the cross-entropy loss\n",
        "    loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PETbM7t1awHg"
      },
      "outputs": [],
      "source": [
        "# Define the transformation for resizing the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((112, 112)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo985pzsfBMT"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the ImageFolder dataset\n",
        "dataset_dir = \"casia-webface\"\n",
        "dataset = ImageFolder(root=dataset_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ragVfJrvfOJk"
      },
      "outputs": [],
      "source": [
        "# Create a dataloader using the ImageFolder dataset\n",
        "batch_size = 1280\n",
        "shuffle = True\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLLR9QCLfXK6"
      },
      "outputs": [],
      "source": [
        "num_classes = len(dataset.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "if7Omb1pftgJ"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "model = MobileNetV3_Small(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TJrL1uRgxzG"
      },
      "outputs": [],
      "source": [
        "# Define the loss function and the optimizer.\n",
        "criterion = ArcFaceLoss(\n",
        "    embedding_size=model.linear4.out_features,\n",
        "    num_classes=num_classes,\n",
        "    margin=0.5,\n",
        "    scale=64,)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-vYUn_HhfiR"
      },
      "source": [
        "# Trainning Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6wAbQx8h5_g"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHNZL30yh_Ok"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bZGYv5gi5Y2"
      },
      "outputs": [],
      "source": [
        "# If you don't want to train, please load model.pth (weight) to model\n",
        "PRE_TRAINED = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "se7PdWYyhiVi",
        "outputId": "281bdf07-2a54-4e4b-8d91-761fbf4bfc25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/15\n",
            "Batch 0/384, Loss: 9.400459289550781\n",
            "Batch 100/384, Loss: 9.047263145446777\n",
            "Batch 200/384, Loss: 8.981632232666016\n",
            "Batch 300/384, Loss: 8.887411117553711\n",
            "Epoch 1/15\n",
            "Batch 0/384, Loss: 8.71939754486084\n",
            "Batch 100/384, Loss: 8.656660079956055\n",
            "Batch 200/384, Loss: 8.407463073730469\n",
            "Batch 300/384, Loss: 8.265393257141113\n",
            "Epoch 2/15\n",
            "Batch 0/384, Loss: 7.946831703186035\n",
            "Batch 100/384, Loss: 7.817373752593994\n",
            "Batch 200/384, Loss: 7.585287570953369\n",
            "Batch 300/384, Loss: 7.441148281097412\n",
            "Epoch 3/15\n",
            "Batch 0/384, Loss: 7.112764835357666\n",
            "Batch 100/384, Loss: 6.907504081726074\n",
            "Batch 200/384, Loss: 6.585480690002441\n",
            "Batch 300/384, Loss: 6.525500297546387\n",
            "Epoch 4/15\n",
            "Batch 0/384, Loss: 6.133518695831299\n",
            "Batch 100/384, Loss: 6.094368934631348\n",
            "Batch 200/384, Loss: 5.8725786209106445\n",
            "Batch 300/384, Loss: 5.688343524932861\n",
            "Epoch 5/15\n",
            "Batch 0/384, Loss: 5.373782157897949\n",
            "Batch 100/384, Loss: 5.395934104919434\n",
            "Batch 200/384, Loss: 5.149231910705566\n",
            "Batch 300/384, Loss: 5.156480312347412\n",
            "Epoch 6/15\n",
            "Batch 0/384, Loss: 4.764143943786621\n",
            "Batch 100/384, Loss: 4.864708423614502\n",
            "Batch 200/384, Loss: 4.908227920532227\n",
            "Batch 300/384, Loss: 4.555139541625977\n",
            "Epoch 7/15\n",
            "Batch 0/384, Loss: 4.252840995788574\n",
            "Batch 100/384, Loss: 4.284400939941406\n",
            "Batch 200/384, Loss: 4.3842363357543945\n",
            "Batch 300/384, Loss: 4.324163913726807\n",
            "Epoch 8/15\n",
            "Batch 0/384, Loss: 4.001554012298584\n",
            "Batch 100/384, Loss: 4.004400253295898\n",
            "Batch 200/384, Loss: 4.010893821716309\n",
            "Batch 300/384, Loss: 4.088633060455322\n",
            "Epoch 9/15\n",
            "Batch 0/384, Loss: 3.4888367652893066\n",
            "Batch 100/384, Loss: 3.77079439163208\n",
            "Batch 200/384, Loss: 3.8073019981384277\n",
            "Batch 300/384, Loss: 3.8062081336975098\n",
            "Epoch 10/15\n",
            "Batch 0/384, Loss: 3.365528106689453\n",
            "Batch 100/384, Loss: 3.3082966804504395\n",
            "Batch 200/384, Loss: 3.230863571166992\n",
            "Batch 300/384, Loss: 3.1516354084014893\n",
            "Epoch 11/15\n",
            "Batch 0/384, Loss: 3.1524837017059326\n",
            "Batch 100/384, Loss: 3.156970500946045\n",
            "Batch 200/384, Loss: 3.117388963699341\n",
            "Batch 300/384, Loss: 3.0485806465148926\n",
            "Epoch 12/15\n",
            "Batch 0/384, Loss: 3.1534268856048584\n",
            "Batch 100/384, Loss: 2.9389419555664062\n",
            "Batch 200/384, Loss: 3.217205047607422\n",
            "Batch 300/384, Loss: 3.0197386741638184\n",
            "Epoch 13/15\n",
            "Batch 0/384, Loss: 3.0102105140686035\n",
            "Batch 100/384, Loss: 2.888958692550659\n",
            "Batch 200/384, Loss: 3.1415963172912598\n",
            "Batch 300/384, Loss: 3.119157075881958\n",
            "Epoch 14/15\n",
            "Batch 0/384, Loss: 2.8204405307769775\n",
            "Batch 100/384, Loss: 2.9406278133392334\n",
            "Batch 200/384, Loss: 3.054198741912842\n",
            "Batch 300/384, Loss: 2.9312562942504883\n"
          ]
        }
      ],
      "source": [
        "if not PRE_TRAINED:\n",
        "  EPOCH_NUM = 15\n",
        "  for epoch in range(EPOCH_NUM):\n",
        "    print(f\"Epoch {epoch}/{EPOCH_NUM}\")\n",
        "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      embeddings = model(inputs)\n",
        "\n",
        "      loss = criterion(embeddings, targets)\n",
        "\n",
        "      # Backward pass and optimization\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch_idx % 100 == 0:\n",
        "        print(f\"Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item()}\")\n",
        "\n",
        "    # Update the learning rate scheduler\n",
        "    lr_scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o_kRGGBfQsok"
      },
      "outputs": [],
      "source": [
        "if not PRE_TRAINED:\n",
        "  # Specify the file path where you want to save the model\n",
        "  file_path = 'model_adam.pth'\n",
        "\n",
        "  # Save the model\n",
        "  torch.save(model.state_dict(), file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BHRSwJ9jtDX8"
      },
      "outputs": [],
      "source": [
        "!cp /content/model.pth /content/gdrive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHM4XGdGaQBC"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FEk8IRU30lO5"
      },
      "outputs": [],
      "source": [
        "\n",
        "if PRE_TRAINED:\n",
        "  model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "# Remove last FC layer\n",
        "model.linear4 = nn.Identity()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B4Uwg2ietwnJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8d69WSkLvyNW"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the ImageFolder dataset\n",
        "!rm -rf ThreeF/.git\n",
        "val_dataset_dir = \"ThreeF\"\n",
        "val_dataset = ImageFolder(root=val_dataset_dir, transform=transform)\n",
        "# Create a dataloader using the ImageFolder dataset\n",
        "batch_size = len(val_dataset)\n",
        "shuffle = True\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P80aPCBtw1rf",
        "outputId": "547f9ee0-0e39-48fe-9b02-ffeca4d554f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "641"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FGpbvPiVwSwW"
      },
      "outputs": [],
      "source": [
        "total_correct = 0\n",
        "total_wrong = 0\n",
        "total_samples = 0\n",
        "threshold = .3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8uICjcxwdsH"
      },
      "outputs": [],
      "source": [
        "for i in range(len(val_dataset)-1):\n",
        "  data = dataset[i][0] # Get the data point\n",
        "  label_i = dataset[i][1] # Get the label\n",
        "  # Compute the embedding for the data point\n",
        "  with torch.no_grad():\n",
        "    data = data.unsqueeze(0).to(device)\n",
        "    embedding_i = model(data)\n",
        "\n",
        "  for j in range(i+1,len(val_dataset)):\n",
        "    data = dataset[j][0]\n",
        "    with torch.no_grad():\n",
        "      data = data.unsqueeze(0).to(device)\n",
        "      embedding_j = model(data)\n",
        "      label_j = dataset[j][1]\n",
        "\n",
        "    similarity_score = F.cosine_similarity(embedding_i,\n",
        "                                           embedding_j,\n",
        "                                           dim=1)\n",
        "\n",
        "    if similarity_score.item() >= threshold  and label_i == label_j:\n",
        "      total_correct += 1\n",
        "    if ((similarity_score.item() >= threshold  and label_i != label_j) or\n",
        "      (similarity_score.item() < threshold  and label_i == label_j)):\n",
        "      total_wrong += 1\n",
        "    total_samples +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chdP52hj6arj"
      },
      "outputs": [],
      "source": [
        "\n",
        "FPR = total_wrong / (total_wrong + total_samples - total_correct)\n",
        "TPR = total_correct / total_samples\n",
        "\n",
        "print(\"False Positive Rate (FPR):\", FPR)\n",
        "print(\"True Positive Rate (TPR):\", TPR)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}